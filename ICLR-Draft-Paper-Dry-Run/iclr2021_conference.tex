\documentclass{article} % For LaTeX2e
\usepackage{iclr2021_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

% I got these from this guide:
% https://shantoroy.com/latex/how-to-write-algorithm-in-latex/
% Which I use to highlight how we do the experiment.
\usepackage{algorithm}
\usepackage{arevmath}
\usepackage[noend]{algpseudocode}


\title{Exploring Neural Network Modularity \\ Using Model Stitching}

% Authors must not appear in the submitted version, you uncomment a line below
% which is labeled "iclrfinalcopy" to anonymize or not.
\author{Adriano Hernandez, Rumen Dangovski \& Peter Y. Lu \thanks{You can find our other work at \url{http://www.a14z.blog/}, \url{http://super-ms.mit.edu/rumen.html}, and \url{https://peterparity.github.io/} respectively.} \\
MIT EECS\\
Cambridge, MA 02139, USA \\
\texttt{\{adrianoh,rumenrd,lup\}@mit.edu}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
We expand \textit{model stitching} (Lenc \& Vedaldi 2015) as a methodology to compare neural networks.
Previously, Bansal, Nakkiran \& Barak used it to compare the representations learned by differently seeded and/or trained neural networks.
We use it to compare the representations learned by neural networks with different architectures.
This gives us insight into the modular structure of neural networks, by helping us map consecutive sequences of layers from one network to those of another.
We think of these sequences of layers as "modules" which may or may not have similar functionality to those of another network.
\end{abstract}


%
%
% Everything below this line
% is the original ICLR template.
% I keep it here specifically for
% the purpose of reminding me of how to do various things...
% I need to figure out how to get citations in there...
% 
% Papers to cite:
% https://arxiv.org/abs/2106.07682 (Revisiting Model Stitching)
%
%
%
%
%%
% https://arxiv.org/abs/2108.01661 (Grounding Representation Similarity with Statistical Testing)
%
% Start here: https://bair.berkeley.edu/blog/2021/11/08/similarity/.
% From this one they basically are trying to create a benchmark to test if a test of similarity is
% good or not. So for example you give them something like CKA or CCA and then they find whether it's
% a good measure or not. However, this "good measure" measure is for A SPECIFIC TASK. So, they are testing
% if FOR A SPECIFIC TASK the measure of similarity is able to discern differences (where accuracy is used
% to tell if the two models are actually different). I'm guessing it's rather harder to use just accuracy
% because it's unclear how you should compare specific layers. They use linear probes (linear classifiers
% trained on top of the intermediate layers we want to compare). They also use accuracy of the whole
% network (though unless you isolate the specific section you change in the network).
%
% Sensitivity: meaningful change is made to a representation => the similarity measure should reflect it.
% Specificity: non-meaningful change is made to a representation => similarity does not change much.
%
% Principle components refers to the principle components as defined by Principle Component Analysis (PCA)
% Read: https://en.wikipedia.org/wiki/Principal_component_analysis. The most informative components
% are the largest ones according to PCA (or at least they can be sorted that way).
%
% It was hard for me to understand what the similarity measures were doing. I need to take a statistics class.
% I also need to review, probably, some aspects of linear algebra or optimization.
%
% I did not totally finish this paper since it was hard to read for me. I will want to write or speak about
% what they are measuring. Here (below) is an outline:
% 1. Definitions of similarity metrics f (OOD and/or linear probe accuracy).
% 2. Definitions of models S (NLP and Vision) and how they were trained
% 3. Descriptions of intuitive tests. We run a test and measure f over it.
%   a. Sensitivity: 
%   b. Specificity: 
% 4. Description of a more rigorous operation
%  a. Definition: pick f (a function from the representation to a real number) as our "accuracy metric"
%  and S as our set of representations to measure similarity. Pick an A inside S (probably the one from the
%  the model with the highest accuracy, or just pick arbitrarily). For all B in S (including cases where
%  A = B) find d(A, B) using the similarity or dissimilarity metric "d" which we are testing, and also find
%  |f(A) - f(B)| which is the variation in "accuracy." Then find Corr(d(A, B), |f(A) - f(B)|) where Corr is
%  a measure of correlation. They use "Tau" and "Rho" which are the Kendall and Spearman measures of
%  correlation, respectively.
%  b. Benchmark 1: layer depth (i.e. which layer).
%  c. Benchmark 2: principle component deletion.
%  d. Pre-training Seed and/or Fine-tuning Seed. For the layer depths the pre-training seed is also varied.
%  For vision the training seed is used (they are Res-Net-14's trained from scratch). For vision no tests seem
%  to be done for PWCCA. I did not read why.
%
% Things that remain to be understood by me:
% 1. The specifics of their experiments (the models, the data, etcetera).
% 2. The definitions of correlation and whether a better "Corr" function might exist.
% 3. The relation between the Wikipedia definitions of "sensitivity" and "specificity" and the usage
%  of those words in the paper (I think it's just meant colloquially, but it's not totally clear).
% 4. The computation and meaning of principle components.
% 5. The meaning and computation of the different similarity metrics. Not only did I not understand them
%  very well, at times I did not even parse them properly.

%%
%% From Revisiting Model Stitching %%
% Understanding intermediate layers using linear classifier probes
% Learning internal representations by error propagation
% Towards understanding learning representations: To what extent do different neural networks learn the same representation, 2018
% Do wide and deep networks learn the same things? uncovering how neural network representations vary with width and depth
% Convergent learning: Do different neural networks learn the same representations?
% Bad global minima exist and sgd can reach them. 
% Insights on representational similarity in neural networks with canonical correlation
% Similarity of neural network representations revisited
% Deep residual learning for image recognition
% Linear mode connectivity and the lottery ticket hypothesis
% On the surprising similarities between supervised and self-supervised models
% Multimodal neurons in artificial neural networks.
%
%

% There is a strict upper limit to 8 pages
% Do NOT refer to the line numbers it automatically generates in your paper
% 
% 
% 
\section{Introduction}

\subsection{Motivation}
This will discuss why we are doing this. The main goal is to understand neural networks, but we can think of this
attempt to understand "modules" as a great boon to transfer learning and cheap computation since it may allow us to
have the tools necessary to do a lot of iterative tinkering with architectures in an empirical way.

\subsection{Stitching}
This will discuss how stitching works on a high level. It will not introduce any mathematical formalisms or notation.
Those will probably be used later.

\subsection{Related Approaches}
This will discuss things like CKA, CCA, Procrustes, and stitching without differnet architectures.

\subsection{Preliminary Results}
Here we will analyze our preliminary results and give a high level summary. Currently, my results are disorganized in a bunch
of .txt log files. I need to get them into figures and tables that are interpretable by us humans (including me).

% Notational notes for myself:
%    %% Stitching %%
% A_{i,j} is the module from i to j inclusive
% A_{\leq N} is the prefix (i.e. module from 0 to N inclusive)
% A_{\geq K} is the suffix of all layers after K.
% AB_{i \rightsquigarrow | \rightarrow \not{\rightarrow} j} is the stitch from A to B from layer i to layer j
%   depeneding on whether the accuracy is unknown, high, or low (so representations are unknown, similar, or differnet)
% To refer to the outputs of networks we use the letter R for representation. For the output of network A
% from layer i we use R_{A, i}. This'd be the input for network A at layer i + 1 or some sort of stitch.
%    %% Mappings %%
% A \rightarrow B
% 
% 
\section{Experimental Setup}
\subsection{Definitions}
To explain our experiment and its goals we must define a few terms. These give us a simple language we may
use to discuss the idea of "modular mappings" of neural networks, which is an idea meant to help us understand how
neural networks are functionally similar.

\subsubsection*{Basic Definitions}
\begin{itemize}
   \item Prefix: the first \(N\) layers of a neural network, \(A\). The prefix has length \(N\). We may call the prefix function \(A_{\leq N}\).
   \item Suffix: the last \(M\) layers of a neural network \(B\). The suffix has length \(M\). We may call the suffix function \(B_{\geq K}\) where if there are \(L\) layers, \(K=L-M+1\).
   \item Module: a subsequence of consecutive layers in a neural network, similar to the notion of a "substring" in computer systems. It can also be thought of as a prefix of a suffix, or a suffix of a prefix. It is denoted with the start and ending layers (inclusive). For example "\(C_{2,3}\)" is the module with layers 2 and 3 of network \(C\). It takes in the output from the first layer outputs the third layer's output. Note that single layers can be modules (i.e. \(C_{1,1}\) is both the first layer and the first possible module of \(C\)).
   \item Submodule: a module inside a module. for example, \(C_{2,2}\) is a submodule of \(C_{2,3}\).
   \item Supermodule: a module within which there is a module.
   \item MLP (Multilayer Perceptron): a network comprised only of (FC) fully connected layers. We use exclusively the ReLU activation function.
   \item CNN (Convolutional Neural Network): a network whose prefix uses convolutional (Conv) layers and suffix uses one or two FC layers for classification. We only use the ReLU activation function.
\end{itemize}

\subsubsection*{Stitching}
We define stitching in the same way as Bansal et. al. We stitch in only two ways: between fully-connected layers
we stitch using linear layers, while between convolutional layers we use 1x1 convolutions. Say we wish to stitch
two networks \(A\) and \(B\) with lengths \(a\) and \(b\). We will stitch the output of layer \(i\) from \(A\) into layer \(j+1\) in \(B\). That
is to say we will input \(R_{A,i}\) where \(R_{B,j}\) is expected through a stitch (and thus be able to compare those two 
representations using the accuracy of the network). We take our stitch \(S\) and define the stitched network \(AB_{i \rightsquigarrow j}\)
as \(B_{\geq b-j+1} \circ S \circ A_{\leq i}\). If that resulting stitched network has a high accuracy, we infer that the
aforementioned representations are similar and we use the notation \(AB_{i \rightarrow j}\). If the resulting network has low accuracy,
we infer that the two representations are not similar and we use the notation \(AB_{i \not{\rightarrow} j}\). If the resulting network
has high accuracy for a given stitch we say that the two networks are "stitchable" at those layers, and otherwise we say they are not
stitchable.

Recall that the stitch is a learned transformation. That is to say, we use gradient descent to approximate the best possible stitch
for any given pair of layers, while freezing all the layers of the two networks.

\subsubsection*{Representational Mappings}
We frame them in terms
of a mapping between pairs of networks \(A, B\), where \(A\) has at most as many layers as \(B\).

We may roughly establish the mapping as follows: for each representation \(R_{A,i}\)
in \(A\), where \(i\) denotes that the representation is the output of layer \(i\), the representation is associated (i.e. "mapped")
to \(R_{B,j}\), the representation output by layer \(j\) in \(B\), if \(R_{B,j}\) is the most similar representation to \(R_{A,i}\) over all possible \(j\) and the similarity is nearly maximal (that is to say, the accuracy of the stitched network \(AB_{i \rightarrow j}\) is close to 100\%)\footnote{Note that we could also define it as "if it is sufficiently similar." We neglect this for now since we wish to enforce that the mapping be a mathematical mapping. If our analysis yields otherwise, then we will revise this definition.}.
Intuitively this says that those two representations are, to an extent, interchangeable.  We hope that this mapping will be injective and monotonic.
By monotonic we simply mean that if \(i_{1} < i_{2}\), \(i_{1}\) maps to \(j_{1}\), and \(i_{2}\) maps to \(j_{2}\), then it should be the case that \(j_{1} < j_{2}\).

The precise reader will note that while the representations may be interchangeable in one direction they may not be in both, depending on the type of stitch. That is to say, \(R_{A,i}\) may be stitchable into the layer expecting \(R_{B, j}\), while 
it is not possible to stitch \(R_{B,j}\) into the layer expecting \(R_{A,i}\)\footnote{If it is necessary, we may henceforth call "the layer in network \(D\) execting \(X\) for any \(X\) to be the "expectant of \(X\) in \(D\)." Generally, I'd like to define some more terms and clean up my language, a lot, to make this easy to read.}.
However, since we are using linear transformations or 1x1 convolutions are our stitches, this should only be the case for drastic changes in dimensionality. We will not explore this yet. Nonetheless, we will use a precise notation to specify whether two layers
are stitchable in one direction, the other, or both. Specifcially, we use \(\rightarrow\) and \(\leftarrow\) to signify which layer\footnote{Or... representation. We need more precise language here.} can be stitched in which other. Generally, though
we will use \(\rightarrow\) and simply swap the order of the operands if need be. If we wish to express that both directions are stitchable we will use \(\leftrightarrow\). Thus, if we can stitch layers \(i\) and \(j\) in networks \(A\) and \(B\) respectively,
in both directions, we can refer to their stitched networks as \(AB_{i \leftrightarrow j}\) and \(BA_{j \leftrightarrow i}\), depending on the order of composition. Moreoer, when we define a representational mapping, we may define it in either direction or in both,
using the following shorthand: \(A \rightarrow B\), \(B \rightarrow A\), \(A \leftrightarrow B\) or \(B \leftrightarrow A\). We define the two-way mapping as the mapping induced by all the layer pairs \(i\) and \(j\) in \(A\) and \(B\) respectively, such that those
layers map to eachother in each of the one-way mappings (i.e. in either direction they are, colloquially speaking, the most similar layer)\footnote{This can also be defined as a union over the two mappings' pairs}. Note that the two-way mapping is not a mathematical
mapping since not all elements in the domain are guaranteed an entry in the range\footnote{You can define the layers/their corresponding representations in one network in the domain and the others as the range, choosing which network is which based on what is most convenient to you.}.

\subsubsection*{Modular Mapping}
Additionally to the notion of a representational mapping, we establish a more general notion\footnote{Representational mappings are the same as modular mappings of layers.} of
a "modular" mapping based on modules: continuous subsequences of layers. The modular mapping allows us to
create a meaningful mathematical mapping between two neural networks. It helps us describe which modules
of each network are "interchangeable" with modules in the other network, giving us a notion of shared functionality\footnote{We have discussed a potential experiment in which we try to "swap out" intermediate sequences of layers for two networks. This is covered by the experimental scheme we have due to the fact that we do representational mappings in both ways. One only needs to interpret representational mappings to find modular mappings, not do more work. By finding two representational mappings for the ends of the module that was "swapped out" we can infer that it is possible to swap out.}.

A modular mapping is a mapping from modules of one network \(A\) to modules of another network \(B\). It is denoted by \(A \Rightarrow B\). Two modules \(A_{i_1,i_2}\) and \(B_{j_1, j_2}\) are mapped
if \(\exists BA_{j_1-1 \rightarrow j_1} \land \exists AB_{i_2 \rightarrow j_2+1}\). Basically, if for some pair of stitches \(S_1, S_2\), the accuracy is high for \(B_{>j_2} \circ S_1 \circ A_{i_1,i_2} \circ S_2 \circ B_{<j_1}\).
For a specific mapping of two modules we use the notation \(A_{i_1, i_2} \Rightarrow B_{j_1, j_2} \). Due to the unidirectional nature of representational mappings, modular mappings are also unidirectional. However, if a two-directional
mapping exists on each end of each module\footnote{I think this is correct but very confusing. The reason is that the two-way representational mapping considers layer weights (i.e. edges) and not layer representations. The layer to which you map is not the layer from which you map in the reverse since it is the expectant. I've been super sloppy and need to do a better job here.}, then we can use the notation \(A_{i_1, i_2} \Leftrightarrow B_{j_1, j_2}\). If we consider only pairs that are two-way mappable we can define the two-way modular mapping \(A \Leftrightarrow B\).

We wish to find an ideally mononic modular mapping between two networks. We present a very simple algorithm\footnote{There is a factor of 2 optimization by calculating the representational similarity if you continue to assume/enforce monotonicity.}
Our algorithm (shown below) finds the first modular mapping it can that is monotonic\footnote{A non-monotonic mapping can be found with a simple brute force which maybe I can outline in the appendix. It can be transformed into a modular mapping by iteratively merging modules where there is an order flip, if those are found. Also note this algorithm is a bit sloppy.}.
\begin{algorithm}
\caption{Monotonic Modular Mapping (informal)}
\begin{algorithmic}[h]
\Procedure{Find \(A \Rightarrow B\)}{} 
      \State Pretrain \(A\) and \(B\) seperately
      \State \(A\) has length \(N\)
      \State \(B\) has length \(M\)
      \State Find \(A\rightarrow B\)
      \State Find \(B\rightarrow A\)
      \State \(i_{start} = 0\)
      \State \(j_{start} = 0\)
      \For{\(i_{end} \in [0, N]\)}
         \For{\(j_{end} \in [j_{start}, M]\)}
            \If{\(A_{i_{end}} \rightarrow B_{j_{end}}\)}
               \State Register \(A_{i_{start}, i_{end}} \Rightarrow B_{j_{start}, j_{end}}\)
               \State \(i_{start} = i_{end} + 1\)
               \State \(j_{start} = j_{end} + 1\)
               \State Break Inner Loop
            \EndIf
         \EndFor
      \EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Hypotheses}
Now that we know how to talk about modules, we introduce 4 main idealized cases that may present themselves when we
try to modularly map two different neural networks of different sizes. We assume that these mappings are all monotonic.
\begin{itemize}
   \item Layer to layer (L2L) mapping: single layers (in shorter networks) may have the same functionality as single layers in longer networks. Additional layers in longer networks introduce new functionality. This mapping is injective, but not surjective.
   \item Layer to module (L2M) mapping: single layers (in shorter networks) may have the same functionality as modules in longer networks. The long networks have the same functionality, but better. This mapping is injective and ideally surjective.
   \item Module to module (M2M) mapping: modules (in shorter networks) may have the same functionality as modules in longer networks. This mapping is injective and ideally surjective.
   \item No (N) mapping: single layers (in shorter networks) do not share any functionality with any layers in longer networks. This mapping is not surjective.
\end{itemize}

Of course, it is possible that our mappings will not be monotonic. However, we will assume that they will be. Even under this assumption, it is also possible that we may have L2L 
mapping within certain modules in any two networks, followed by L2M mapping, M2M mapping, or N mapping. We will seek to describe pairs of networks, such that both are sequences of supermodules,
such that within each pair of corresponding supermodules the submodules pertain to only one of the four hypotheses (or more generally, follow an interpretable pattern).
Informally, we may call these the "realms" of a modular mapping. The realms induce an informal, two-way, mapping of supermodules, where two supermodules are mapped to eachother if and only if
within them there is a human-understandable, repeatable pattern to the modular mapping. So, if two networks have a one to one L2L mapping for their first 3 layers, then the two 3-layer prefixes of
these networks form two supermodules that are mapped to eachother, forming an L2L realm. The subsequent modules in either network may form other realms, such as an N mapping realm. I will add a
diagram for this, but you can find it on the powerpoint in the google drive. Because networks will have different numbers of layers, some realms will only include layers from one network (as in the
the layers of an ideal L2L modular mapping between 2 networks of different lengths).

Thus, due to the many types of mappings, we summarize to ensure that our ideas are perfectly clear to the reader. This summary is not mathematically rigorous, but
only meant to highlight the key intuitions behind these terms. The mapping types are as follows:
\begin{itemize}
   \item (One-way) Representational mapping: a mapping where \(R_{A,i}\) is mapped to \(R_{B,j}\) if the former may be input through a stitch into the spot of the latter in \(B\). This is a one-way mapping.
   \item Two-way representational mapping: a mapping where we only consider \(R_{A,i}\) mapped to \(R_{B,j}\) if they are both mapped to each other in the one-way mappings.
   \item (One-way) Modular mapping: when a module from one network may be replaced through two stitches with that from another network. This is defined using two opposite way representational mappings into and out of the module.
   \item Two-way Modular mapping: when two modules from two networks are both one-way modular mappable.
   \item Realms (or Realm Mapping): a direction-agnostic pairing of supermodules such that across the pair of modules, mappings are either all L2L, L2M, M2M, N, or otherwise following an interpretable pattern. This can be defined for either one-way modular mapping or the two-way modular mapping.
\end{itemize}

\subsection{Goals}
The goal for our experiments was to understand the similarities between different neural networks by searching
for modular mappings. To help us understand if different architectures were learning the same sorts of solutions,
we trained them seperately and tried to find elegant modular mappings between them. More broadly, we wish to confirm
that modular mappings are exclusively monotonic and explore the different modular mapping realms that exist across pairs
of relevant networks.

%%% The more precise, concrete section begins here
\subsection{Networks and Dataset}
We focused on varying only the random seed of the neural network. To simplify our analysis we also used the MNIST dataset
(do to its small size) and relatively small neural networks. We established two classes of networks: CNNs and MLPs.
We only compared CNNs (Convolutional Neural Networks) with other CNNs and MLPs (Multilayer Perceptrons) with other MLPs.
Our choice of networks were the following:
\begin{itemize}
   \item CNNs
   \begin{itemize}
      \item \(C_{3,2}\): a zero-padded CNN with 3 convolutional layers and 2 linear layers. Of the two linear layers, one is to flatten the tensor into a representation space and the other is to project it onto the ten classes and use a softmax.
      \item \(C_{4,2}\): a zero-padded CNN with 4 convolutional layers and 2 linear layers. The linear layers are the same as \(C_{3,2}\) and first 3 convolutional layers are also the same.
      \item \(C_{10,2}\): a zero-oadded CNN with 10 convolutional layers and 2 linear layers. The linear layers are the same as the previous two CNNs, while the first 4 convolutional layers are the same as those for \(C_{4,2}\).
   \end{itemize}
   \item MLPs
   \begin{itemize}
      \item \(F_{3}\): a 3 layer MLP.
      \item \(F_{5}\): a 5 layer MLP whose first 3 layers are identical in architecture to those of \(F_{3}\).
      \item \(F_{8}\): an 8 layer MLP whose first 5 layers are identical in architecture to those of \(F_{5}\).
   \end{itemize}
\end{itemize}

For training we trained for 40 epochs or until high accuracy using stochastic gradient descent with no
weight decay or learning rate schedule. Batch normalization or other such techniques were not used.

\subsection{Tests and Controls}
TODO\footnote{I HAVE INSERTED THESE TODOS WHILE I WORK TO REMIND MYSELF OF WHAT REMAINS TO BE DONE.}

We established some basic controls to
have a baseline for the similarities we'd expect between representations that we think are already similar
as well as for similarities we'd expect from representations that we are fairly certain should be
different. They are the following:
\begin{itemize}
   \item We stitched corresponding layers of differently seeded instances of the same archiecture. This is a control and we expect it to have high similarity.
   \item We stitched non-corresponding layers of the same network. This is a control and we should expect it to be different.
   \item We stitched non-corresponding layers of different instances of the same architecture. This is a control to give us additional information to the previous control.
   \item For all pairs of different architectures in each class, we wanted to copmare each layer in each with each layer in the other, both ways. This enables us to infer modular mappings from respresentational mappings.
\end{itemize}

At the same time, we wished to make sure to test each instance various times so that we could ensure that the observed behavior was not spurious.
To be able to test all these cases many times we ensured in the testing algorithm (expounded below) that the following cases were
each tested multiple times:
\begin{itemize}
   \item Two copies of the same network architecture with the same weights
   \item Two copies of the same network architecture with different weights
   \item Each pair TODO
\end{itemize}

\subsection{Testing Algorithm}
TODO
%%% The precise, concrete section, describing the experiments, ends here

\section{Results}
\subsection{Summary}
Here we will have a summary and repetition of our results. We will want some figures in general. This will
include grid heatmaps (so we can see which layers were similar to which others), line plots of stitching loss
for different pairs of networks for different 

\subsection{Figures}
Here we have some results' figures to highlight what happened.

% Figures that make sense when they are in black and white are ideal
\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
\end{center}
\caption{Sample figure caption.}
\end{figure}

\subsection{Tables}
Here we have some tables.

\begin{table}[h]
\caption{Sample table title}
\label{sample-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

\subsection{Stitching CNNs with CNNs}
This is where we will have visualizations and tables for what happened when
we tried to stitch CNNs with CNNs.

\subsubsection{Stitching MLPs with MLPs}
This is where we will have visualizations and tables to explore what happend
when we tried to stitch MLP (Multi-layer-perceptron, i.e. FC end to end) networks.

\subsubsection{Stitching MLPs with MLPs}
Please flesh this out.

\section{Analysis and Interpretation of Results}
\subsection{Interpretation}
It didn't work.

\subsection{Significance}
What this means for the future and the field.

\section{Conclusions}
We'll write our conclusions in a nice format here.

\section*{Acknowledgments}
Thank you to the SuperUROP benefactors (MIT EECS) for funding this project.

\bibliography{iclr2021_conference}
\bibliographystyle{iclr2021_conference}

\appendix
\section{Appendix}
More information will be added here with regards to less interpretable (or "failed")
results, experimental details that were omitted in the previous section, and so forth.

\end{document}
